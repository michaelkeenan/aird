---
layout: argument
title: "Our understanding of how to align systems will advance"
breadcrumbs: The Alignment Problem:the-alignment-problem,Our understanding of how to align systems will advance:alignment-advances-equally
---

<blockquote>
Maybe capabilities and alignment will advance together, and thus advanced artificial intelligence might be safe “by default”. For example, consider DALL-E. It paints these pictures based on textual descriptions. Painting accurate pictures is exactly what we want, and it wouldn’t be useful if it did not do that. Progress means making it aligned, in this case. 
<ul><li>It is true that capabilities and alignment might advance together. But it is not guaranteed.</li>
<li>TODO<br/>> put the rihgt quote here<br/>> put the same quote int the previous chapter<br/>> expand the points here<br/>> synchronize this and the previous chapter</li>
</ul>0:48:07.8 Interviewee: I'm actually far less worried about the technical side of this. I just finished reading this book about von Neumann, that's a little cute biography of him, and there's a part where he says, supposedly, that people who think mathematics is complicated only say that because they don't know how complicated life is. And I'm totally messing with the phrasing, but something like that. I actually think any technical problems in this area will be solved relatively easily compared to the problem of figuring out what human values we want to insert into these. 
</blockquote>

<li>Maybe alignment will be solved during the normal cause of AI research.</li>
<li>But maybe not!</li>
<li>Alignment and Capabilities are not the same. You can have very advanced systems with bad alignment, for example a GPT-style text generator that seems really smart - but constructs elaborate falsehood that seem true at first glance.</li>
<li>Even if it seems likely that alignment will advance alongside capabilities, we don’t have any guarantee about that. The danger from a badly aligned system seems really high - so it’s probably worth worrying about that.</li>
<li>Safety often lags behind in the deployment of innovative technology. <li>There is a long history of dangerous technology being deployed prematurely, before the technology was understood well enough to be safe. Some examples:</li>
<ul><li>Radioactive toothpaste being sold in Germany in the 1920s</li>
<li>Early passenger aircraft (like the de Havilland Comet ) having rectangular windows, before it was understood that rectangular features put too much stress on the airframe - leading to several disasters.</li>
<li>The Therac-25 radiation treatment machine which killed several people due to a programming error.</li>
<li>The dangerous reactor design which contributed to the Chernobyl disaster.<br/></li>
<a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
<div>&#10149; <a href='the-alignment-problem.html#argnav'>Go back</a></div>
<div>&#10149; <a href='#feedback'>Send Feedback</a></div>
