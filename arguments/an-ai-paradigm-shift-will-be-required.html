---
layout: argument
title: "An AI paradigm shift will be required"
breadcrumbs: Generally capable AI systems:when-agi,Never:never,An AI paradigm shift will be required:an-ai-paradigm-shift-will-be-required
---

<blockquote>
I think currently, the way AI problems are defined is also more in the nature of pattern recognition than general intelligence, right? Like Translate is a one-to-one mapping, even image classification is just like, looking at an image data, tell me what it is, and that kind of stuff. But general intelligence is a lot more things. It's like, learning how to... Not just knowing what to say, in a particular situation, for instance, but being able to have a conversation deciding which of the alternatives, of things you say, will lead in a particular direction. And even, I mean, It involves a lot of emotional aspects also, right? Like empathy, compassion, or even negative aspects like jealousy, and rancor, and stuff like that. But I mean, it involves a lot of things, which, like I said, I don't think can be put in the form of a mathematical problem. So I think the current approach to AI, which is– take a task, make a mathematical formulation, and then solve it– isn't really suitable for general intelligence. 
</blockquote>

<div>A paradigm shift might be required. But that paradigm shift might come in just ten years, or twenty. This is soon enough to make AGI a significant concern. We cannot know when these paradigm shifts occur, and just how much (or little) new insights will be required.</div>
<div>Even if massive innovation is required, it seems likely we would eventually get there given the increasing investment in AI technology.</div>
<a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
