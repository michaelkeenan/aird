---
layout: argument
title: "Conclusion"
breadcrumbs: Conclusion:conclusion
---
<p>Thank you for reading through this interactive guide on the potential risks from advanced AI systems. We hope that it has been an engaging experience for you , and that it this felt like a productive exploration of part of the discussion about the development and deployment of highly capable AI.</p>
<p>This series was originally based on arguments and counterarguments discussed during a set of interviews Vael Gates had with ~100 AI researchers, and we’re eager thankful to add your insights and perspectives. Your beliefs, in terms of agreements and disagreements, have been added to the plots below describing what readers of this site think about potential risks from AI (INCLUDE PLOTS) . If you’re interested in further explorations of this topic, you can see , and you’re welcome to explore what the original AI researcher s interviewees believed by reading via their original transcripts (LINK) and quantitative summaries (LINK). Additionally, our “Resources” and “Next Steps” pages provide more information.</p>
<p>If you found this content intriguing, we consider mitigating potential risks from advanced AI a critical issue in our time, and our “Resources” and “Next Steps” pages provide more information if you’d like to learn more. If you are interested in getting involved in this effort, work in technical research on AI alignment is especially needed, and we would be happy to talk with you about these opportunities (LINK).</p>
<p>Finally, we welcome any feedback that you may have, whether you found this content frustrating or interesting. Please don't hesitate to share your thoughts with us (LINK) , and thanks again for your interest in discussions about potential risks from advanced AI .</p>
<a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
