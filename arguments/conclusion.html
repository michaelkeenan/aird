---
layout: argument
title: "Conclusion"
breadcrumbs: Conclusion:conclusion
---
<p>Thank you for reading through this interactive guide on the potential risks from advanced AI systems. We hope that it has been an engaging experience, and that it felt like a productive exploration of part of the discussion about the development and deployment of highly capable AI.</p>
<p>This series was originally based on arguments and counterarguments discussed during a set of interviews Vael Gates had with 97 AI researchers, and we’re eager to add your insights and perspectives. Your beliefs, in terms of agreements and disagreements, have been added to the plots below describing what readers of this site think about potential risks from AI (INCLUDE PLOTS). If you’re interested in further explorations of this topic, you can see what the original AI researcher interviewees believed by reading their original transcripts and quantitative summaries on the page <a href='../interviews' >Interviews</a>. Additionally,  our <a href='../resources' >Resources</a> and <a href='../what_can_i_do' >What can I do?</a> Steps” pages provide more information.</p>
<p>If you are interested in getting involved in this effort, <em>work in technical research on AI alignment</em> is especially needed, and we would be happy to talk with you about these opportunities (LINK this’ll be the heading partway down the What can I do page).</p>
<p>Finally, we welcome any feedback that you may have, whether you found this content frustrating or interesting. Please don't hesitate to share your thoughts with us <a href='mailto:{{site.email}}' >via email</a>.</p>
<a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
