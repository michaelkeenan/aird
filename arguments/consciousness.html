---
layout: argument
title: "AI cannot be conscious in the way a human is"
breadcrumbs: When will we get generally capable AI systems?:when-agi,Never:never,AI cannot be conscious in the way a human is:consciousness
---
<div><blockquote> I don’t believe an AI can be conscious in the sense of having a felt experience. Therefore, I doubt that it can truly be generally intelligent. (made up)</blockquote></div>
<ul><li>How consciousness arises and whether a computer program can ever be conscious are open questions.</li>
<li>It is unclear if consciousness (in the sense of “felt experience”) is required for AGI.</li>
<li>If an AI is conscious, it would have profound and likely troubling implications. However, for the discussion here it’s not important whether or not systems are conscious, because we are discussing potential risks from advanced AI that arise out of certain capabilities. The arguments do not require assumptions on whether or not the system would be conscious.</li>
<li>We consider the potential risk of these advanced AI systems severe enough (potential existential risk) to discuss even without the added possible complication of consciousness arising in these systems.</li>
