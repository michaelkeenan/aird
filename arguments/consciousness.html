---
layout: argument
title: "AI cannot be conscious in the way a human is"
breadcrumbs: WhenAGI:when-agi,Never:never,AI cannot be conscious:consciousness
---
<div><blockquote> I don’t believe an AI can be conscious in the sense of having a felt experience. Therefore, I doubt that it can truly be generally intelligent. (made up)</blockquote></div>
<ul><li>How consciousness arises and whether a computer program can ever be conscious are open questions.</li>
<li>It is unclear if consciousness (in the sense of “felt experience”) is required for AGI.</li>
<li>If an AI is conscious, it would have profound and likely troubling implications. However, for the discussion here it’s not important whether or not systems are conscious. We are discussing potential risks that arise out of certain capabilities in advanced systems. The arguments do not require assumptions on whether or not that system would be conscious - all we are concerned about here is the behaviour.</li>
<li>We consider the potential risk of these advanced AI systems severe enough (potential existential risk) to discuss even without the added complication of consciousness arising in these systems.</li>
