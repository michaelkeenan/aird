---
layout: argument
title: "Never"
breadcrumbs: When will we get generally capable AI systems?:when-agi,Never:never
---
<blockquote>“No, I don't think we'll get there. I think it's too broad. Everything that we see currently in AI that works well is really specific and trained for a specific task, and once you try to even just go multi-task and try to solve like three tasks together, it always goes south. So I think really a general solution like that is not going to work. (mdkoi_Sam, Pos. 12)”
On the other hand, the other type of research that I think is also connected to my own research is that we need to get more inspired by the human brain and by animal brains. So when, during evolution, brains have also scaled, right? But they didn't scale uniformly. It was not like we got a mouse brain and just scale it in all different dimensions to get to the human brain. Human brain scaled compared to mouse brain, but they scaled differently. They scaled in different dimensions differently. So we need to really understand the scaling underlying brains’ evolution, throughout evolution, in order to know how exactly we need to scale these models to get different types of abilities in different environments, different environmental pressures, and so on. So, yeah, I think in a combination of all these approaches, we might get a better chance of getting to this kind of artificial intelligence or artificial general intelligence. (o00lg_Sam, Pos. 14)
“[Something like a text summarization machine] can learn something outside what it was fed, but I don't still think that [it has] the vision, the potential to see something like the intuition, the intuition that a human has that “this might work”, and “this might not work”. I think it comes with a lot of things, with emotions, with our personal emotions, our personal experience. [We can feed our personal experiences into a computer] but I think there's an emotional sixth sense kind of thing through which CEOs take a lot of decisions that if they have a limited capital, how much to invest on which one. There is a lot of intuition game going on [..] For example, one of its venture is actually on loss, so the robot might not ever try to push any capital on it, but a CEO might have the vision that, "No, I should still go on pushing on that direction" and once it works it will give so much profit that it would be the best option for me. So I don't think that robots can take those kind of decisions. (jrf1z_VaelLabel, Pos. 24-25)
I think humans probably cannot create something which has this cognitive capacity, at least, the same level as we have. So I think we'll have something which is specific for each task, but this general, the cognitive intelligence… I know it will be too hard to be a scientist or a CEO. I think it's never, never going to happen. (cmjut_Sam, Pos. 12)
</blockquote>
It's hard to know what technologies are possible or impossible, given the absence of proof. Tech forecasting is notoriously difficult. However, here are some reasons we expect AGI eventually:
<ol><li>History of people being wrong about what’s impossible</li>
<ol><li>Consider, for example, that just two years before the first flight of the Wright Brothers, Wilbur Wright himself predicted it was at least fifty years away (by his own account).</li>
<li>In 1933, Ernest Rutherford declared that the idea of harnessing atomic energy was “moonshine”. Shortly thereafter (the very next day, according to some accounts) Leo Szilard discovered the possibility of a chain reaction.<br/>In 1939, Enrico Fermi proclaimed that the chain reaction was just a “remote possibility” - four years later, he himself oversaw the world’s first nuclear reactor.<br/>One night in 1933, the world’s pre-eminent expert on atomic science, Ernest Rutherford, declared the idea of harnessing atomic energy to be “moonshine.” And the very next morning Leo Szilard discovered the idea of the chain reaction. In 1939, Enrico Fermi told Szilard the chain reaction was but a “remote possibility,” and four years later Fermi was personally overseeing the world’s first nuclear reactor.</li>
<li>In an informal review, <a href='predictions of the “Big Three” science fiction writers'>https://www.cold-takes.com/the-track-record-of-futurists-seems-fine/</a> of the 20th century were categorized and evaluated - at least 31% of their predictions turned out to be correct.</li>
</ol><li>Ridiculous amount of progress made so far, which people were wrong about, since deep learning revolution</li>
<ol><li>TODO look up deep learning predictions from 10 years ago and examples in which they were wrong</li>
</ol><li>Lots of investment in this, time, money, people, with international economic interests and massive increases in investment [since 2010](</li>
<li>https://venturebeat.com/ai/report-ai-investments-see-largest-year-over-year-growth-in-20-years/</li>
<li>)</li>
<li>Evolution got there in a pretty “dumb” way: Intelligence arose as a side effect of biological agents roaming in a complex environment and competing for fitness advantage.</li>
<li>[Could add a point about how even if the chance is relatively smfffall-- like 10-30%-- AI might still be one of the most transformative technologies in expectation]</li>
<div><a href='/arguments/biology-special.html'>There is something special about biology which we will never be able to put into machines</a></div>
<div><a href='/arguments/seems-weird.html'>I don’t know, but truly intelligent machines - that seems really weird</a></div>
<div><a href='/arguments/creativity.html'>AI will never be able to have true creativity</a></div>
<div><a href='/arguments/understand-brain-first.html'>We would need to understand the brain first, and this is a big obstacle</a></div>
<div><a href='/arguments/i-don’t-see-a-reason-for-us-to-even-want-that.html'>I don’t see a reason for us to even want that</a></div>
<div><a href='/arguments/i-can’t-see-it-based-on-current-progress.html'>I can’t see it based on current progress</a></div>
<div><a href='/arguments/an--ai-paradigm-shift-will-be-required.html'>An AI paradigm shift will be required</a></div>
<div><a href='/arguments/surely-this-would-be-bad-and-people-would-stop-it.html'>Surely this would be bad and people would stop it</a></div>
<div><a href='/arguments/embodiment-is-necessary.html'>We need embodiment - the AI needs a body and actuators, and sensors</a></div>
<div><a href='/arguments/consciousness.html'>AI cannot be conscious in the way a human is</a></div>
