---
layout: argument
title: "Regulators will take care of this"
breadcrumbs: The importance of more safety work:the-importance-of-more-safety-work,Regulators will take care of this:regulators-will-take-care-of-this
---

<blockquote>
So I think in the similar sense, for this kind of new AI, yeah, again, the government will be lagging behind. But once this kind of technology become mature and people starting to get used to it, or more people getting used to it, then probably some people will stand up and tell government... Talk to the government and say, "Hey, you need to regulate this, that, those. There are a lot of bad people use this to scam other people, blah, blah, blah." And I think at the end somebody will try to fix it. At least pointing out, this actually need to be regulated. So I'm not, actually, not really that negative about this thing. I know, I think, and I agree, when this kind of new technology comes out in the very beginning stage, negative thing can happen. But after some fluctuation, ultimately, will converge and slow down, and that's what I think. 
</blockquote>

<li>Policymakers are very busy, and they know much less about AI than you.</li>
<ul><li>Do you expect them to do something? If yes, what?</li>
<li>Also, would they be able to react quickly enough? What if AGI is being developed in secret, or breakthroughs occur suddenly?</li>
<li>International coordination might be required to avoid an arms race towards AGI - do you think this can be done in time?<br/>
<a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
