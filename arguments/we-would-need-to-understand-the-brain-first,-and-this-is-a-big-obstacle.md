---
layout: argument
title: We would need to understand the brain first, and this is a big obstacle
breadcrumbs: When will we get generally capable AI systems?:when-agi,Never:never,We would need to understand the brain first and this is a big obstacle:we-would-need-to-understand-the-brain-first,-and-this-is-a-big-obstacle
---
<blockquote>0:11:18.6 Interviewee: But at the same time, having human-like capabilities is very, very hard because... Primarily because we do not understand the brain as it exists. Now, of course, there has been a different trajectory where people have sort of said, "Okay, we don't care about what the brain does or how it works, we just want to keep on playing with the permutation and then combination of how the layers are arranged, what layers are to be put in, and that is how we come up with a network. And then that just solves the task at hand. So that's one way to do it. And that's perfectly all right. But if you were to mimic the brain as is, we need to have a lot more studies and we need to have a lot more going on the neuroscience front and on the cognitive psychology front. Vision scientists need to come in and really bridge that gap, that is when I think we can achieve somewhere close to artificial general intelligence.  (dwe14_VaelLabel, Pos. 13)
I'm not so sure that we'll have a general AI because this all started with the false analogy that artificial neural networks are analogous to biological neural networks. And the thing is we don't really understand how the brain really works,  in depth. We have some idea that there are different parts of the brain and this and that happens but we don't really know. We cannot replicate it, we cannot create an artificial biological brain. So saying that artificial neural network simulates the brain, and if you'll just keep increasing the number of neurons, number of layers and throwing a lot of compute power and a lot of data to do something, I don't think we'll have a general AI. We really need to understand how the brain works if we are talking about that. (oju8k_VaelLabel, Pos. 13)</blockquote>
Here are some examples of what we can do with current machine learning techniques (without having gained much understanding of the way the brain works):<br/>[textblock:examples-of-progress]
<ul><li>PaLM (2022) was the most compute intensive model ever trained at the time of release [</li>
<li>https://ourworldindata.org/grapher/ai-training-computation?time=2017-08-04..2022-07-01</li>
<li>]. It achieved state-of-the-art few-shot performance across numerous difficult NLP tasks, including natural language inference, common-sense reasoning, in-context reading comprehension and question answering. The system is also able to explain novel jokes.</li>
</ul><figure><img src='https://lh3.googleusercontent.com/2B7BhXeGRepb-bc6OK5uCCEIQpFeo1in4oAar95po8YbAZjEChZvGEA9_9Vd9GxYBCOZBeFdUy_WDUxKeWihO0Fwn2ZDwkNRrgNoqzDbl-6hP6vEbDyBrPavt7sGdCKSq6U6OC_iwI_G2090rynzpl1X5eGSrBe5Zs6Sgb0tgEi8MePzqrRCaDG3pDA_es93AhE' referrerpolicy='no-referrer'/><figcaption markdown='1'>PaLM capabilities gain as a function of model size - note that new capabilities suddenly appear as the model grows
</figcaption></figure>
<figure><img src='https://lh3.googleusercontent.com/r7FO9wE93R0mp-rFDZVWKqwqKbSOalaMbppC7-LAU4VIA3_DP-d2eTGbgO1TjnLukQWFKYWJyZ5TnSHhHDrMyVvty7Q4v8fd7HS2zrLNIXXA5Bbgr2H9wvvKAkd65-DoECY0pUZLskkqV2TEqY6tdzeps-zmruMbM_LB8u38Xtbj5Twtlzd1OYo4b4NnPZq0r2s' referrerpolicy='no-referrer'/><figcaption markdown='1'>Explaining Jokes using PaLM (2-shot) [https://storage.googleapis.com/pathways-language-model/PaLM-paper.pdf] 
</figcaption></figure>
<ul><li>The interesting thing here is that scaling alone, without adding new insights, creates qualitative differences in abilities. PaLM gained these abilities (like explaining jokes and answering physics questions) without anyone having properly understood how the human brain does them.</li>
</ul><li>Dall-E 2, which shows creativity and the ability to understand concepts</li>
<figure><img src='https://lh3.googleusercontent.com/aX5BOIi8Beg54IB9uYxBJhhber-gJds8HSaSETjRfn-RV4DuamOwmVHy7w6oXRZjT-3U4osW66jFtYONpB5GS3MIYCCtcev8-VqeAUTbwV3eG5UoDCQsCQTvq-Qm8eFpLD32mH4XhnnKfdAVuR42bJozSbcs2GBz4k3xEi6hNV9WsEpINe44TTsdLdth9kjJmkE' referrerpolicy='no-referrer'/><figcaption markdown='1'>Dall-E 2 samples, source: <a href='OpenAI'>https://cdn.openai.com/papers/dall-e-2.pdf</a> 
</figcaption></figure>
<li>A 2021 paper from Deepmind engaging in a variety of tasks in a virtual environment, and then generalising to novel games never seen in training [</li>
<li>https://www.deepmind.com/blog/generally-capable-agents-emerge-from-open-ended-play</li>
<li>]</li>
<li>TODO: show Imagen examples here, to hit the point home even more how quickly the progress has been in just 1 year</li>
[/textblock]
It is possible that the human brain does something special which does not map onto these ML approaches - but we are currently not sure about that.
<div><a href='/arguments/i-don’t-see-a-reason-for-us-to-even-want-that.html'>I don’t see a reason for us to even want that</a></div>
