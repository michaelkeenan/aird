<div class="page-data" data-page-title="Conclusion"></div><p>Thank you for reading through this interactive guide on the potential risks from advanced AI systems. We hope that it has been an engaging experience for you, and that this felt like a productive exploration of part of the discussion about the development and deployment of highly capable AI.</p>
<p>This series was originally based on arguments and counterarguments discussed during a set of interviews Vael Gates had with ~100 AI researchers, and we’re thankful to add your insights and perspectives. Your beliefs, in terms of agreements and disagreements, have been added to the plots below describing what readers of this site think about potential risks from AI (INCLUDE PLOTS), and you’re welcome to explore what the original AI researchers believed via their original transcripts (LINK) and quantitative summaries (LINK).</p>
<p>If you found this content intriguing, we consider mitigating potential risks from advanced AI a critical issue in our time, and our “Resources” and “Next Steps” pages provide more information if you’d like to learn more. If you are interested in getting involved in this effort, work in technical research on AI alignment is especially needed, and we would be happy to talk with you about these opportunities (LINK).</p>
<p>Finally, we welcome any feedback that you may have, whether you found this content frustrating or interesting. Please don't hesitate to share your thoughts with us (LINK), and thanks again your interest in discussions about potential risks from advanced AI.</p>
<a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
