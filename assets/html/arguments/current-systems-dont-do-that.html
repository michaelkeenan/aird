<div class="page-data" data-page-title="Current systems don’t do that"></div>
<blockquote>

<div>I feel like I don't see why this would ever happen or how this would ever happen in a model, simply because it's not what it was intended to do, and I feel like going out of that scope of initial tasks rarely happens. </div>

</blockquote>

<ul><li>Current AI systems won’t act in that way, but future systems might.</li>
<li>In fact, given certain assumptions, we would expect that systems act in accordance with certain instrumental incentives. [textblock:AllThatIsRequiredForSelfPreservation]</li>
<li>Recent systems like Google PaLM have demonstrated sudden capability gain upon increases in model size. It is difficult to say which additional capabilities could arise in the future as a result</li>
<li>TODO: mention theories on emergence of agency (waiting for response from an expert I contacted)</li>
</ul><a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
