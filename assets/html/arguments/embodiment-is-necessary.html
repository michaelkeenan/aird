<div class="page-data" data-page-title="We need embodiment"></div>
<blockquote>
 It's going to be extremely difficult to develop something that is sufficiently reliable and has an understanding of the world that is sufficiently grounded in the actual world without doing some kind of mimicking of human experiential learning. So I'm thinking: reinforcement learning in robots that actually move around the world. I think without something like that, it's going to be extremely difficult to tether the knowledge and the symbolic manipulation power that the AIs have to the actual contents of the world. 
</blockquote>

<ul><li>Even if it is necessary for a robot to have sensory data in order to achieve AGI, this should not pose a significant obstacle in the long run. If it’s necessary, someone will create it sooner or later.</li>
<li>Even if a large number of sensors and various types of real-world data are required (beyond just one robot), that is also feasible.</li>
<li>Suppose the robot needs a 20-year training process to “grow up,” like a child. That would not be an obstacle either.</li>
<ul><li>The robot wouldn't need to sleep or do many of the other things a human must do.</li>
<li>Human children do many things to learn that require only their mind and don’t involve embodiment—for example, watching movies and reading books. These tasks could be greatly sped up.</li>
<li>If this is actual path towards AGI, then we’d just need to do the training process once—after that, the result could be copied indefinitely. This may be a costly and difficult process, but there’s no reason to think it would be impossible.</li>
</ul><li>If embodiment is necessary, why couldn’t we place a simulated body in a 3D simulated world? A simulated world could contain simulacra of real-world phenomena like human actors and physical processes.</li>
<ul><li>Furthermore, training environments could be tested until one is found that works even better than the real world.</li>
<li>Computer graphics and physics simulation are mature technologies, and can be greatly accelerated compared to real life.</li>
</ul><li>Robotics AI might be lagging behind language AI. But there’s no reason to think it may not catch up in a decade or two. The only effect this would have is a small delay before AGI.</li>
<li>Consider “<a href='https://openai.com/blog/vpt/' target='_blank'>Video PreTraining (VPT)</a> ” research from OpenAI:</li>
<ul><li>In this research, the AI never actually played Minecraft during training, which means this training method had nothing resembling embodiment. Despite this, the AI learned to perform complex actions—just by watching.</li>
<li>Sidenote: A small amount of the training data was labeled (meaning: video frames accompanied by keystroke and mouse data). However, most of the training data consisted of unlabeled video.</li>
</ul><li>Many complex cognitive tasks can be solved using language training only—not even using other sensory data, and certainly no embodiment. Many capabilities have been unlocked just in the past two years by large language models like GPT-3 and PaLM. There is reason to suspect we have not reached the limits of language-based AI, nor the limits of capabilities generated by them.</li>
</ul><a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
