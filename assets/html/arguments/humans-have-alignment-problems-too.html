<div class="page-data" data-page-title="No – humans have alignment problems too"></div>
<blockquote>
Let's say we are so worried that autonomous cars today can lead to some crashes or something, but today on record, the human error or human misjudgment causes much more fatal issues on the road than potentially any AI driven car today. 
Humans fail at their tasks all the time, humans make errors all the time, so if we have a system that has an error threshold that's still better than humans, can we be angry? We can't do any better. Keeping everything else the same, if the decision system that we have fails less than humans, then sure, we don't want to be failing, we want to be perfect, but we can't really complain. It is a situation that we'll have to work at, but that's like everything. There's always room for improvement. 
</blockquote>

<ul><li>Humans have a shared evolutionary prior, which AI does not. Therefore, if an AI is optimizing over reality in some sense, it might end up in a really alien part of that space - alien to humans, because it’s optimizing over a really large space. This space will by necessity contain motivations and actions that seem totally alien to us.</li>
<li>Present-day AIs sometimes find solutions to problems that humans would never think of. So it’s plausible that what an AI does will seem pretty alien and uncommon - which makes it more difficult to reason about it.</li>
<li>AI can duplicate quickly, and a collection of duplicated AIs would be able to collaborate perfectly.</li>
<li>AI could be much more powerful than any one human, or even all humans together.</li>
<li>It’s fine if your child isn’t perfectly aligned with you, because they’re their own person and they have autonomy. People are just pretty easy to control overall - as we understand human psychology, and we all have very roughly the same limitations and boundaries in society. If the AI isn’t aligned with you and gets out of control, it could be quite dangerous.</li>
<li>We’ve got institutions to regulate human conflicts. But governance takes a really long time to develop and won’t keep up with tech progress.</li>
<li>AI could act much quicker than humans.</li>
<li>If we acknowledge that far-greater-than-human-intelligence is possible, then it would be much more powerful than humans and could circumvent the usual checks&balances that mostly prevent misaligned humans from doing very bad things</li>
<li>AGI could be so useful that humans give it great power and responsibility, more than the usual human has.</li>
<li>Human misuse can be a big problem. At some point though, we might have an AI agent, which is smarter than you, trying to optimize the world. And that would be dangerous above and beyond the misuse scenarios.</li>
</ul><a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
