<div class="page-data" data-page-title="Introduction"></div><p>Welcome to this interactive guide on the potential risks from advanced AI systems. We hope this will help you explore some of the ongoing discussion on the development and deployment of highly capable AI systems.</p>
<p>As you go through this guide, you'll encounter a range of arguments and counterarguments related to the potential risks of advanced AI. At the bottom of each page, you'll have the opportunity to select between several answers or counterarguments.</p>
<p>The arguments and counterarguments presented in this guide are based on interviews with 97 AI researchers (92 randomly selected from submissions to NeurIPS or ICLR 2021; 5 selected by recommendation), and reflect the most common perspectives within that population. Embedded quotes are from those interviews. We welcome your feedback and encourage you to get in touch with us, especially if your own views are not represented here. Additionally, if you have any other comments or questions as you go through this interactive guide, please contact us via the feedback button at the bottom of each page.</p>
<p>At times we will entertain thought experiments that would be implausible with current state-of-the-art systems, but might be relevant to future systems. These types of thought experiments often blur the lines between philosophy and computer science. <a href='https://bounded-regret.ghost.io/more-is-different-for-ai/' target='_blank'>Jacob Steinhardt</a> has written about this tension between the “engineering approach” and the “philosophy approach”. He argues that neither of these approaches are satisfying when thinking about future AI systems. Therefore, in this guide we aim for a balanced picture, by supplementing our thought experiments with real-world examples.</p>
<a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
