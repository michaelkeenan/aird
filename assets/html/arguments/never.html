<div class="page-data" data-page-title="Never"></div>
<blockquote>
No, I don't think we'll get there. I think it's too broad. Everything that we see currently in AI that works well is really specific and trained for a specific task, and once you try to even just go multi-task and try to solve like three tasks together, it always goes south. So I think a general solution like that is not going to work. 
</blockquote>


<blockquote>
On the other hand, the other type of research that I think is also connected to my own research is that we need to get more inspired by the human brain and by animal brains. So when, during evolution, brains have also scaled, right? But they didn't scale uniformly. It was not like we got a mouse brain and just scale it in all different dimensions to get to the human brain. Human brain scaled compared to the mouse brain, but they scaled differently. They scaled in different dimensions differently. So we need to really understand the scaling underlying brains’ evolution, throughout evolution, in order to know how exactly we need to scale these models to get different types of abilities in different environments, different environmental pressures, and so on. So, yeah, I think in a combination of all these approaches, we might get a better chance of getting to this kind of artificial intelligence or artificial general intelligence. 
</blockquote>


<blockquote>
[Something like a text summarization machine] can learn something outside what it was fed, but I don't still think that [it has] the vision, the potential to see something like the intuition, the intuition that a human has that “this might work”, and “this might not work”. I think it comes with a lot of things, with emotions, with our personal emotions, our personal experience. [We can feed our personal experiences into a computer] but I think there's an emotional sixth sense kind of thing through which CEOs make a lot of decisions that if they have a limited capital, how much to invest on which one. There is a lot of intuition game going on [...] For example, one of its venture is actually on loss, so the robot might not ever try to push any capital on it, but a CEO might have the vision that, "No, I should still go on pushing on that direction" and once it works it will give so much profit that it would be the best option for me. So I don't think that robots can make those kinds of decisions. 
</blockquote>


<blockquote>
I think humans probably cannot create something which has this cognitive capacity, at least, the same level as we have. So I think we'll have something which is specific for each task, but this general, the cognitive intelligence… I know it will be too hard to be a scientist or a CEO. I think it's never, never going to happen. 
</blockquote>

<div>It's hard to know what technologies are possible or impossible, given the absence of proof. Tech forecasting is notoriously difficult. However, here are some reasons we expect AGI eventually:</div>

<ol><li>History of people being wrong about what’s impossible</li>
<ol><li>Consider, for example, that just two years before the first flight of the Wright Brothers, Wilbur Wright himself predicted it was at least fifty years away (by his own account).</li>
<li>In 1933, Ernest Rutherford declared that the idea of harnessing atomic energy was “moonshine”. Shortly thereafter (the very next day, according to some accounts) Leo Szilard discovered the possibility of a chain reaction.<br/>In 1939, Enrico Fermi proclaimed that the chain reaction was just a “remote possibility” - four years later, he himself oversaw the world’s first nuclear reactor.</li>
<li>In an informal review, <a href='https://www.cold-takes.com/the-track-record-of-futurists-seems-fine/' target='_blank'>predictions of the “Big Three” science fiction writers</a> of the 20th century were categorized and evaluated - at least 31% of their predictions turned out to be correct.</li>
</ol><li>People seem to have not have predicted the amount of progress that would occur during the deep learning revolution; and progress seems to be accelerating.</li>
<ol><li>For example, <a href='https://bounded-regret.ghost.io/ai-forecasting/' target='_blank'>2021 predictions made by experienced forecasters</a> on AI progress on state-of-the-art accuracy on the MATH dataset as well as the Massive Multilanguage Understanding dataset were wildly inaccurate, with <a href='https://bounded-regret.ghost.io/ai-forecasting-one-year-in/' target='_blank'>actual improvement after one year being much higher than predicted</a>. These forecasts were commissioned by researcher Jacob Steinhardt.</li>
</ol><li>Lots of investment in this, time, money, people, with international economic interests and massive increases in investment <a href='https://venturebeat.com/ai/report-ai-investments-see-largest-year-over-year-growth-in-20-years/' target='_blank'>since 2010</a></li>
<li>Evolution got there in a pretty “dumb” way: Intelligence arose as a side effect of biological agents roaming in a complex environment and competing for fitness advantage.</li>
</ol>
<a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
<div><em></em></div>
