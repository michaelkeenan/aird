---
layout: home
title: Home
landing-title: 'AI Risk Discussions'
description: null
image: null
author: null
show_tile: false
---

DRAFT TEXT

Welcome to AI Risk Discussions, a platform created by individuals interested in exploring and discussing the potential risks of advanced AI systems.

*Interviews*

One of our main goals is to facilitate conversations between those concerned about potential risks from advanced AI systems and key stakeholders, especially technical experts in the field: AI researchers. To that end, we have conducted 97 interviews with researchers on their perspectives on current AI and the future of AI, with a focus on risks from advanced AI systems. This collection of interviews offers a wide range of interesting perspectives and can be accessed in the Interviews section, where you can read the raw transcripts (many interviewees gracefully allowed their anonymized transcripts to be shared), view the quantitative analysis, or watch the talk discussing preliminary findings.

*Interactive guide*

To better explore both the interviews and the arguments for potential risks from advanced AI systems, we created an interactive guide to walk through the common arguments, counterarguments, and counter-counterarguments that occurred in the interview series. While the interviews explored many topics, this guide focuses on the parts of the interviews focused on the core arguments around potential risks from advanced AI systems. One advances through the guide like the interviewees did, with agreements and disagreements based on the most common perspectives from AI researchers in the transcripts. At the end, you'll be able to observe what set of agreements/disagreements other people interfacing with this website also had. There is also substantial additional text not present in the interviews: this guide covers interviewee questions, the most common perspectives from AI researchers in response, and additional text describing potential counterarguments that the interviewer could have raised. 

*Resources and getting involved*

For those interested in learning more, we provide several different types of resources: those aimed at the public, those aimed at machine learning researchers, and technical work aimed at AI alignment. We will continue to update this website with new resources as they become available! 

For those concerned about potential risks from advanced AI systems, we also have several recommendations for what one can do to help. In particular, work in technical research on AI alignment is especially needed, and we would be happy to talk with you about these opportunities (LINK).

*About us*

This work was completed by many parties; primary text contributors are Vael Gates, Lukas Trötzmüller (interactive guide), Maheen Shermohammed (quantitative analysis). 