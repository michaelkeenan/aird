---
layout: argument
title: The Alignment Problem
breadcrumbs: The Alignment Problem:the-alignment-problem
---

* Current ML systems can fail in surprising and unexpected ways. [Many examples have been collected](https://docs.google.com/spreadsheets/d/e/2PACX-1vRPiprOaC3HsCf5Tuum8bRfzYUiKLRqJmbOoC-32JorNdfyTiRRsR7Ea5eWtvsWzuxo8bjOxCG84dAg/pubhtml)
* Suppose we have a future “CEO AI” that’s running a company. Their board of directors might give the AI the goal: “Maximize profits without exploiting people, don’t run out of money, and avoid side effects that people would consider objectionable”.
* Currently we find it very challenging to translate these human values, preferences and intentions into mathematical formulations that can be optimized by systems. This might continue to be a problem in the future. 

Would you agree that highly intelligent systems might fail to optimize exactly what their designers intended them to, and this is dangerous?

* “It’s no problem, [we would test it before deploying](/test-before-deploying)”
* “It’s no problem: [if it misbehaves, we shut it down](/we-shut-it-down)”
* “My counterargument is not listed - [send feedback](#feedback)”
* “[Yes, I would agree](/instrumental-incentives)”

<figure style="float: right">
  <img src="{% link assets/images/palm.png %}" alt="Explaining Jokes using PaLM (2-shot)" />
  <figcaption><a href="https://storage.googleapis.com/pathways-language-model/PaLM-paper.pdf">Explaining Jokes using PaLM (2-shot)</a></figcaption>
</figure>

<div style="clear:both">&nbsp;</div>

<h3>Blockquote</h3>
<blockquote>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan faucibus. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis.</blockquote>

* More
* Bulletpoints
* Including:
  * Sub-bulletpoints
  * And such
